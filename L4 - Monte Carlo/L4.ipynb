{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC 480-F25 Lab 4: Agentic Monte Carlo Search\n",
    "### Authors:\n",
    "***[Your Name Here]***\n",
    "\n",
    "California Polytechnic State University, San Luis Obispo;\n",
    "Computer Science & Software Engineering Department\n",
    "\n",
    "### Overview\n",
    "This lab focuses on:\n",
    "*   Understanding and implementing Monte Carlo Search for a complex puzzle (NYT Spelling Bee).\n",
    "*   Improving the random simulation (rollout) process by designing a smarter heuristic.\n",
    "*   Decomposing the Monte Carlo Search algorithm into a multi-agent system using AutoGen.\n",
    "*   Specifying the communication protocols (MCP and A2A) for agent collaboration.\n",
    "*   Analyzing the trade-offs between conventional and agentic implementations of search algorithms.\n",
    "\n",
    "**NOTE:** The Spelling Bee problem definition and a baseline Monte Carlo search function are provided for you. Your work is to improve the heuristic (Part 1) and then re-implement the search using an agentic architecture (Part 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "By the end of this lab, you will be able to:\n",
    "*   Understand the principles of Monte Carlo Search and its trade-offs compared to systematic search algorithms.\n",
    "*   Implement a conventional Monte Carlo Search algorithm by adapting a generalized search framework.\n",
    "*   Design and implement an agentic system to perform and evaluate the random simulations (rollouts).\n",
    "*   Analyze how the number of simulations impacts solution quality and performance.\n",
    "*   Specify the communication patterns (MCP/A2A) required for agents to collaboratively execute and aggregate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "Install the required packages for AutoGen and other utilities. This setup is similar to previous labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"autogen-core\" \"autogen-agentchat\" \"autogen-ext[openai,azure]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Import AutoGen classes, similar to Lab 2 and 3\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.base import TaskResult\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure OpenAI Configuration\n",
    "Set up your Azure OpenAI client configuration. **Remember to replace the placeholder values with your actual deployment details** as you did in previous labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your Azure OpenAI client\n",
    "azure_deployment = \"your-deployment-name\"\n",
    "api_version = \"2024-12-01-preview\"\n",
    "azure_endpoint = \"your-azure-endpoint\"  # e.g., \"https://your-resource-name.openai.azure.com/\"\n",
    "\n",
    "# Ensure your API key is set as an environment variable for security\n",
    "api_key = os.getenv(\"AZURE_SUBSCRIPTION_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"AZURE_SUBSCRIPTION_KEY environment variable not set.\")\n",
    "\n",
    "client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=azure_deployment,\n",
    "    model=\"gpt-5-mini\",\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The NY Times Spelling Bee Problem\n",
    "The following class defines the Spelling Bee problem. It includes methods to check for valid words, calculate scores, and determine if a state is a goal state. You will not need to modify this class, but you should understand its methods. This setup is similar to the problem definition in Lab 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellingBeeProblem:\n",
    "    \"\"\"Defines the NYT Spelling Bee puzzle.\n",
    "    A state is represented by the current word being built (e.g., 'APPLE').\n",
    "    An action is appending a valid letter.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, letters, required_letter, dictionary):\n",
    "        self.letters = set(letters)\n",
    "        self.required_letter = required_letter\n",
    "        self.dictionary = dictionary\n",
    "        self.initial_state = \"\"\n",
    "\n",
    "    def get_successor_states(self, state):\n",
    "        \"\"\"Generate all possible next states (words) by appending one letter.\"\"\"\n",
    "        successors = []\n",
    "        for letter in self.letters:\n",
    "            successors.append(state + letter)\n",
    "        return successors\n",
    "\n",
    "    def is_valid_word(self, word):\n",
    "        \"\"\"Check if a word is a valid solution.\"\"\"\n",
    "        return (\n",
    "            len(word) >= 4\n",
    "            and self.required_letter in word\n",
    "            and word.lower() in self.dictionary\n",
    "        )\n",
    "\n",
    "    def get_score(self, word):\n",
    "        \"\"\"Calculate the score for a valid word.\"\"\"\n",
    "        if not self.is_valid_word(word):\n",
    "            return 0\n",
    "        score = len(word)\n",
    "        if len(word) == 4:\n",
    "            score = 1\n",
    "        if set(word) == self.letters:\n",
    "            score += 7  # Pangram bonus\n",
    "        return score\n",
    "\n",
    "\n",
    "# For this lab, we'll use a small, simple dictionary for demonstration purposes.\n",
    "simple_dictionary = {\"apple\", \"apply\", \"appeal\", \"pale\", \"peel\", \"plea\", \"leap\", \"app\"}\n",
    "puzzle = SpellingBeeProblem(\n",
    "    letters={\"A\", \"P\", \"L\", \"E\", \"Y\"}, required_letter=\"A\", dictionary=simple_dictionary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Conventional Monte Carlo Search and Heuristic Improvement\n",
    "\n",
    "In this part, you will work with a conventional implementation of Monte Carlo Search. The core idea is to evaluate a potential move (i.e., the next state) by running many random simulations (rollouts) from that state and averaging the outcomes.\n",
    "\n",
    "The provided `run_simulation` function uses a **simple heuristic**: it picks the next letter with uniform random probability. Your task is to improve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(\n",
    "    problem: SpellingBeeProblem,\n",
    "    start_state: str,\n",
    "    max_depth: int = 10,\n",
    "    heuristic_fn=None,\n",
    "):\n",
    "    \"\"\"Runs one random rollout from a given state and returns the score.\"\"\"\n",
    "    current_state = start_state\n",
    "    for _ in range(max_depth):\n",
    "        if problem.is_valid_word(current_state):\n",
    "            return problem.get_score(current_state)\n",
    "\n",
    "        possible_next_letters = list(problem.letters)\n",
    "        if not possible_next_letters:\n",
    "            break\n",
    "\n",
    "        if heuristic_fn:\n",
    "            # Use the heuristic to pick the next letter\n",
    "            next_letter = heuristic_fn(current_state, possible_next_letters)\n",
    "        else:\n",
    "            # Default: simple uniform random choice\n",
    "            next_letter = random.choice(possible_next_letters)\n",
    "\n",
    "        current_state += next_letter\n",
    "\n",
    "    return problem.get_score(current_state)\n",
    "\n",
    "\n",
    "def monte_carlo_search(\n",
    "    problem: SpellingBeeProblem,\n",
    "    current_state: str,\n",
    "    num_simulations: int = 100,\n",
    "    heuristic_fn=None,\n",
    "):\n",
    "    \"\"\"Evaluates successor states using Monte Carlo rollouts and chooses the best one.\"\"\"\n",
    "    successors = problem.get_successor_states(current_state)\n",
    "    best_successor = None\n",
    "    best_avg_score = -1\n",
    "\n",
    "    for successor in successors:\n",
    "        total_score = 0\n",
    "        for _ in range(num_simulations):\n",
    "            total_score += run_simulation(problem, successor, heuristic_fn=heuristic_fn)\n",
    "\n",
    "        avg_score = total_score / num_simulations\n",
    "        print(f\"Successor '{successor}' has average score: {avg_score:.2f}\")\n",
    "\n",
    "        if avg_score > best_avg_score:\n",
    "            best_avg_score = avg_score\n",
    "            best_successor = successor\n",
    "\n",
    "    return best_successor, best_avg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Task (Part 1): Implement an Improved Heuristic\n",
    "Create a new heuristic function `improved_heuristic`. This function should be \"smarter\" than a simple random choice. It takes the `current_word` and a list of `possible_letters` and returns the chosen next letter.\n",
    "\n",
    "**Ideas for your heuristic:**\n",
    "*   **Letter Frequency:** Prioritize letters that are more common in English.\n",
    "*   **Avoid Repetition:** Penalize adding a letter that is already in the word.\n",
    "*   **Seek the Required Letter:** If the required letter isn't in the word yet, give it a higher probability.\n",
    "*   **Pangram Seeking:** Prioritize using all unique letters from the puzzle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "# A simple letter frequency map for English (you can find more detailed ones online)\n",
    "ENGLISH_LETTER_FREQ = {\n",
    "    \"E\": 12.7,\n",
    "    \"T\": 9.1,\n",
    "    \"A\": 8.2,\n",
    "    \"O\": 7.5,\n",
    "    \"I\": 7.0,\n",
    "    \"N\": 6.7,\n",
    "    \"S\": 6.3,\n",
    "    \"H\": 6.1,\n",
    "    \"R\": 6.0,\n",
    "    \"D\": 4.3,\n",
    "    \"L\": 4.0,\n",
    "    \"C\": 2.8,\n",
    "    \"U\": 2.8,\n",
    "    \"M\": 2.4,\n",
    "    \"W\": 2.4,\n",
    "    \"F\": 2.2,\n",
    "    \"G\": 2.0,\n",
    "    \"Y\": 2.0,\n",
    "    \"P\": 1.9,\n",
    "    \"B\": 1.5,\n",
    "    \"V\": 1.0,\n",
    "    \"K\": 0.8,\n",
    "    \"J\": 0.2,\n",
    "    \"X\": 0.2,\n",
    "    \"Q\": 0.1,\n",
    "    \"Z\": 0.1,\n",
    "}\n",
    "\n",
    "\n",
    "def improved_heuristic(current_word, possible_letters: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Implement your smarter heuristic here.\n",
    "    This function should return a single chosen letter from `possible_letters`.\n",
    "    \"\"\"\n",
    "    # --- YOUR CODE GOES HERE ---\n",
    "    # This function uses the probabilities from ENGLISH_LETTER_FREQ to make a weighted random choice.\n",
    "    # You should try to improve it more. Replace this!\n",
    "\n",
    "    # For example, create a list of weights for each possible letter\n",
    "    weights = [\n",
    "        ENGLISH_LETTER_FREQ.get(letter.upper(), 1.0) for letter in possible_letters\n",
    "    ]\n",
    "\n",
    "    # Use random.choices to pick a letter based on the weights\n",
    "    chosen_letter = random.choices(possible_letters, weights=weights, k=1)[0]\n",
    "\n",
    "    return chosen_letter\n",
    "    # --- END OF YOUR CODE ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run and Compare Heuristics\n",
    "Now, run the Monte Carlo search with both the baseline (no heuristic) and your improved heuristic to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Running with Baseline Heuristic (Uniform Random) ---\")\n",
    "best_move_base, best_score_base = monte_carlo_search(\n",
    "    puzzle, current_state=\"\", num_simulations=500\n",
    ")\n",
    "print(\n",
    "    f\"\\nBest next letter with baseline heuristic: '{best_move_base}' with score {best_score_base:.2f}\\n\"\n",
    ")\n",
    "\n",
    "print(\"--- Running with Improved Heuristic ---\")\n",
    "best_move_improved, best_score_improved = monte_carlo_search(\n",
    "    puzzle, current_state=\"\", num_simulations=500, heuristic_fn=improved_heuristic\n",
    ")\n",
    "print(\n",
    "    f\"\\nBest next letter with improved heuristic: '{best_move_improved}' with score {best_score_improved:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection (Part 1)\n",
    "*Write a few sentences here reflecting on your heuristic. Did it perform better than the baseline? Why or why not? What other factors could you incorporate to make it even better?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Agentic Implementation of Monte Carlo Search\n",
    "\n",
    "Now, you will refactor the Monte Carlo search into a multi-agent system using AutoGen. This exercise is similar to the task decomposition in Lab 2, where you assign specialized roles to different agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Task (Part 2): Design and Implement the Agentic System\n",
    "\n",
    "You need to create and configure a team of agents to perform the search. We suggest the following roles, which follow a **Manager-Worker** pattern:\n",
    "\n",
    "1.  **Orchestrator Agent (Manager)**: Manages the overall process. It identifies the possible next moves (successors), asks for them to be evaluated, and then chooses the best one.\n",
    "2.  **Simulator Agent (Worker)**: Its only job is to run a single random simulation for a given state using your `improved_heuristic`.\n",
    "3.  **Aggregator Agent**: This agent receives multiple simulation scores for a single successor state and calculates the average.\n",
    "\n",
    "First, define the system prompts for these agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- YOUR CODE GOES HERE: Define system messages for each agent ---\n",
    "\n",
    "orchestrator_system_message = \"\"\"\n",
    "You are the Orchestrator.\n",
    "Your job is to find the best next letter in the Spelling Bee puzzle.\n",
    "1. You will be given the current word and the list of possible next letters.\n",
    "2. For each appropriate single-letter successor word, ask the Simulator to evaluate it.\n",
    "3. The Simulator will produce the average score (higher is better) for each word you ask it to evaluate.\n",
    "4. You may repeat steps 2-3 as many times as you like. Once you decide on a successor, say \"SUCCESSOR: <letter>.\"\n",
    "\"\"\"\n",
    "\n",
    "simulator_system_message = \"\"\"\n",
    "You are a simulation agent.\n",
    "For every word the Orchestrator asks you to evaluate, you will run an appropriate number of simulations using the \\\n",
    "provided `run_simulations_tool` which returns the average score to report back.\n",
    "\"\"\"\n",
    "\n",
    "# --- END OF YOUR CODE ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering Tools for Agents (MCP)\n",
    "\n",
    "To allow agents to perform actions, we need to register functions as tools they can call. This is an example of the Model Context Protocol (MCP), where we define a clear schema for how the agent can interact with its environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function the Simulator agent will call.\n",
    "def run_simulations_tool(word: str, num_simulations: int) -> float:\n",
    "    \"\"\"Runs num_simulations simulations for a given word and returns the average score.\"\"\"\n",
    "\n",
    "    # We use the improved heuristic from Part 1\n",
    "    scores = [\n",
    "        run_simulation(puzzle, start_state=word, heuristic_fn=improved_heuristic)\n",
    "        for _ in range(num_simulations)\n",
    "    ]\n",
    "    avg_score = sum(scores) / len(scores) if scores else 0.0\n",
    "    print(f\"Ran {num_simulations} simulations for word '{word}'. Average score: {avg_score:.2f}\")\n",
    "\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Agents and Group Chat\n",
    "Now, create the agents and set up the group chat for them to collaborate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- YOUR CODE GOES HERE: Instantiate the agents ---\n",
    "\n",
    "orchestrator_agent = AssistantAgent(\n",
    "    name=\"Orchestrator\", system_message=orchestrator_system_message, model_client=client\n",
    ")\n",
    "\n",
    "simulator_agent = AssistantAgent(\n",
    "    name=\"Simulator\",\n",
    "    system_message=simulator_system_message,\n",
    "    model_client=client,\n",
    "    tools=[run_simulations_tool],\n",
    ")\n",
    "\n",
    "# --- END OF YOUR CODE ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Agentic Workflow\n",
    "Finally, create a group chat, add your agents, and initiate the task. The initial message to the Orchestrator will kick off the process. The communication between agents is a form of Agent-to-Agent (A2A) interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_agentic_monte_carlo(verbose: bool = False):\n",
    "    termination = TextMentionTermination(\"SUCCESSOR:\")\n",
    "    groupchat = RoundRobinGroupChat(\n",
    "        [orchestrator_agent, simulator_agent],\n",
    "        max_turns=50,  # Prevent infinite loops\n",
    "        termination_condition=termination,\n",
    "    )\n",
    "\n",
    "    # Define the initial task for the Orchestrator\n",
    "    initial_state = \"\"\n",
    "    successor_states = puzzle.get_successor_states(initial_state)\n",
    "\n",
    "    task = f\"\"\"\n",
    "    The current word is empty. Find the best next letter to add.\n",
    "    The possible successor words to evaluate are: {successor_states}.\n",
    "    For each successor, ask the Aggregator to evaluate it with an appropriate number of simulations.\n",
    "    Once all are evaluated, state the best one and then say TERMINATE.\n",
    "    \"\"\"\n",
    "\n",
    "    result: TaskResult = await groupchat.run(task=task)\n",
    "\n",
    "    # Parse the result to extract the chosen successor letter\n",
    "    output = result.messages[-1].content\n",
    "    if verbose:\n",
    "        print(\"\\n--- Full Agentic Monte Carlo Conversation ---\")\n",
    "        for msg in result.messages:\n",
    "            print(msg.content)\n",
    "    if output and \"SUCCESSOR:\" in output:\n",
    "        chosen_letter = output.split(\"SUCCESSOR:\")[-1]\n",
    "        chosen_letter = chosen_letter.strip().replace(\".\", \"\").replace(\",\", \"\")\n",
    "\n",
    "        print(\"\\n--- Agentic Monte Carlo Result ---\")\n",
    "        print(f\"Chosen next letter: '{chosen_letter}'\")\n",
    "    else:\n",
    "        print(\"No valid successor found.\")\n",
    "\n",
    "\n",
    "# To run the async function in Jupyter\n",
    "await run_agentic_monte_carlo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection & Analysis (Part 2)\n",
    "\n",
    "##### What worked well?\n",
    "*Reflect on where the agentic decomposition was effective. Was the division of labor clear?*\n",
    "\n",
    "##### What struggled?\n",
    "*Note any challenges. Did agents misunderstand each other? Was the communication flow inefficient?*\n",
    "\n",
    "##### Agentic vs. Conventional Implementation\n",
    "*Compare the agentic implementation to the conventional one in Part 1. What are the advantages and disadvantages of the agentic approach in terms of code complexity, modularity, and extensibility?*\n",
    "\n",
    "##### Communication Design (MCP/A2A)\n",
    "*Describe your MCP and A2A design. For MCP, what was the schema for your `run_simulation` tool? For A2A, describe one key interaction (e.g., Orchestrator -> Aggregator). What was the purpose and what information was exchanged?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and Next Steps\n",
    "#### Key Takeaways\n",
    "*   **Monte Carlo Search**: [Your insights about using random sampling for search]\n",
    "*   **Heuristic Design**: [What you learned about guiding random search effectively]\n",
    "*   **Agentic Decomposition**: [Your thoughts on breaking down algorithms into agent roles]\n",
    "\n",
    "#### References\n",
    "*   Lab 4 Overview Document\n",
    "*   AutoGen Documentation: https://microsoft.github.io/autogen/\n",
    "*   Russell, S., & Norvig, P. (2020). *Artificial Intelligence: A Modern Approach* (4th ed.)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
