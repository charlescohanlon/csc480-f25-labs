{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364ef75b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "# CSC 480-F25 Lab 6: Knowledge Graphs\n",
    "\n",
    "### Author:\n",
    "***[Team Member 1]***\n",
    "\n",
    "California Polytechnic State University, San Luis Obispo;\n",
    "Computer Science & Software Engineering Department\n",
    "\n",
    "### Overview\n",
    "\n",
    "This lab covers Knowledge Graphs with Neo4j—from standing up a local graph database and writing basic Cypher, to designing a practical schema with constraints and indexes, then (optionally) using an agentic system to help plan and create that schema. You’ll work with a small investigative dataset (people, events, locations, evidence, and cases) and translate flat CSVs into a connected graph that supports rich querying and reasoning.\n",
    "\n",
    "Specifically, you will:\n",
    "- Install and connect to Neo4j Desktop; verify connectivity using the Python driver.\n",
    "- Inspect the provided CSVs and understand how entities (nodes) and relations (edges) map to a graph model.\n",
    "- Create an example schema via Cypher with unique constraints and helpful indexes, using a provided helper for executing queries.\n",
    "- Optionally, invoke an AutoGen-based agentic workflow (Azure OpenAI) to propose and materialize the schema automatically.\n",
    "- Prepare the knowledge graph you’ll query and reason over in the next lab.\n",
    "\n",
    "By the end, you should be able to model a domain as a graph, set up constraints and indexes to keep it clean and fast, load/validate data with Cypher, and set the stage for reasoning and querying in Lab 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deea034b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Setting up Neo4j (Desktop)\n",
    "\n",
    "### Installation\n",
    "\n",
    "Follow the instructions at this [link](https://neo4j.com/docs/desktop/current/installation/). Install version 2.0.5 for whatever OS your system uses. You'll have to create an account.\n",
    "\n",
    "### Creating a Graph DB with Neo4j desktop\n",
    "\n",
    "Open the Neo4j desktop application and follow the directions to create your first Neo4j instance.\n",
    "This instance acts as your DBMS, which manages Graph DBs.\n",
    "Then, follow the instructrions [here](https://neo4j.com/docs/desktop/current/operations/database-management/) to create and host a Graph DB on your system with local host. When you create a DB you'll be prompted to create a password for the DB. It can be as simple as you'd like, as it's only accessible by users on your system, but you need to remember it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c566f4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%pip install pandas neo4j neomodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check that the database is set up correctly\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "username = \"neo4j\"  # the default user created when you set up Neo4j\n",
    "password = \"simple123\"  # example password\n",
    "hostname = \"127.0.0.1\"\n",
    "port = 7687  # default Bolt protocol port\n",
    "uri = f\"bolt://{hostname}:{port}\"\n",
    "\n",
    "# Test with the native neo4j driver to see if we get more details\n",
    "try:\n",
    "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"RETURN 1 as test\")\n",
    "        print(f\"Connection successful! Result: {result.single()['test']}\")\n",
    "    driver.close()\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2155a92",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the data files\n",
    "!unzip -o L6-7_data.zip -d ./L6-7_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d05dc0d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "### L6-7_data: High-level dataset breakdown\n",
    "\n",
    "This dataset models the Kristin Smart case with clearly separated node CSVs (entities) and relationship CSVs (edges), using Neo4j-style import headers. Here’s the global picture and what each file contributes.\n",
    "\n",
    "#### Entities (nodes)\n",
    "\n",
    "- Person.csv\n",
    "  - Key columns: `id`, `name`, `type`, `status`, `dob`\n",
    "  - Examples: KS (Kristin Smart – Victim), PF (Paul Flores – Suspect/Murderer), RF (Ruben Flores – Accessory), family and witnesses.\n",
    "  - Notes: `type` captures role (Victim, Suspect, Family, Witness); `status` captures lifecycle (e.g., Convicted, Deceased, Key Witness).\n",
    "\n",
    "- Location.csv\n",
    "  - Key columns: `id`, `name`, `type`, `address`, `city`\n",
    "  - Examples: PARTY_LOC (Crandall Way party house), MUIR_HALL, SANTA_LUCIA (dorms), RF_HOME, PF_HOME_LA, EXCAVATION_16 (dig site), MONTEREY_COURT.\n",
    "  - Notes: `type` distinguishes residences, dorms, search sites, and venues.\n",
    "\n",
    "- Event.csv\n",
    "  - Key columns: `id`, `type`, `date`, `description`\n",
    "  - Examples: DISAPPEAR (last sighting), DECLARE_DEAD, DIG_2016, SEARCH_RF_HOME, ARRESTS, TRIAL_START, PF_GUILTY.\n",
    "  - Notes: Seminal milestones with dates and human-readable descriptions.\n",
    "\n",
    "- Evidence.csv\n",
    "  - Key columns: `id`, `type`, `status`, `description`\n",
    "  - Examples: EARING (lost by police), TRUCKS (seized/analyzed), DRUGS (found at PF_HOME_LA), BIOLOGICAL (under RF deck), VOLKSWAGEN, VIDEOS.\n",
    "  - Notes: `status` reflects chain-of-custody or analysis (Seized/Analyzed, Unknown, etc.).\n",
    "\n",
    "- Case.csv\n",
    "  - Key columns: `id`, `name`, `status`, `dateOpened`\n",
    "  - Example: CASE_KS (Murder of Kristin Smart; status shows conviction and the case open date).\n",
    "\n",
    "#### Relationships (edges)\n",
    "\n",
    "- Person_Person_Rel.csv (Person → Person)\n",
    "  - Columns: `:START_ID(Person)`, `:END_ID(Person)`, `:TYPE`, `relationshipType`\n",
    "  - Examples: `ACCOMPANIED_BY` (who walked with whom), `FAMILY_RELATIONSHIP` (e.g., PF → RF Father).\n",
    "  - Notes: `relationshipType` adds semantic detail (e.g., \"Last Known Person\", \"Spouse\").\n",
    "\n",
    "- Person_Location_Rel.csv (Person → Location)\n",
    "  - Columns: `:START_ID(Person)`, `:END_ID(Location)`, `:TYPE`, `date`, `time`\n",
    "  - Examples: `ATTENDED_PARTY_AT` (KS/PF/others → PARTY_LOC), `LAST_SEEN_NEAR` (KS → SANTA_LUCIA), `LIVED_AT`/`RESIDENCE_OF` for dorm/home ties.\n",
    "  - Notes: `date`/`time` may be missing for some records; treat as optional properties.\n",
    "\n",
    "- Event_Evidence_Location_Rel.csv (Evidence → Location)\n",
    "  - Columns: `Event_Evidence_Location_Rel:START_ID`, `:END_ID`, `:TYPE`, `date`\n",
    "  - Examples: `FOUND_AT` (BIOLOGICAL → RF_HOME), `SEIZED_FROM` (VOLKSWAGEN/DRUGS/VIDEOS → RF_HOME/PF_HOME_LA) with dates.\n",
    "  - Notes: Despite the header name, the `START_ID` values correspond to Evidence IDs (e.g., DRUGS, VOLKSWAGEN). Use as Evidence → Location.\n",
    "\n",
    "- Case_Related_Rel.csv (Person → Case)\n",
    "  - Columns: `:START_ID(Person)`, `:END_ID(Case)`, `:TYPE`, `outcome`\n",
    "  - Examples: `VICTIM_IN` (KS → CASE_KS), `SUSPECT_IN` (PF → CASE_KS, outcome=Convicted), `ACCUSED_IN` (RF → CASE_KS, outcome=Acquitted), `FILED_CIVIL_SUIT_IN` (family → CASE_KS).\n",
    "  - Notes: `outcome` is optional and captures legal results when present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781c0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "data_path = Path(\"./L6-7_data\")\n",
    "data = [(file.name, pd.read_csv(file)) for file in data_path.glob(\"*.csv\")]\n",
    "\n",
    "data_str = \"\"\n",
    "for name, df in data:\n",
    "    data_str += f\"File: {name}\\nDataframe head:{df}\\n\" + \"=\" * 90 + \"\\n\\n\"\n",
    "\n",
    "# The names and dataframes for each file\n",
    "print(data_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bccdf2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: An Example Knowledge Graph Schema\n",
    "\n",
    "The following creates an example knowledge graph schema, and instantiates it in your Neo4j graph DB instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f793746a",
   "metadata": {},
   "source": [
    "### First, a tool for executing Cypher queries in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5492c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "\n",
    "# Tool function to execute Cypher queries\n",
    "def execute_cypher_query(query_str: str, description: str = \"Executing query\", verbose: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Executes a Cypher query on the Neo4j database.\n",
    "\n",
    "    Args:\n",
    "        query_str: The Cypher query to execute\n",
    "        description: A description of what the query does\n",
    "\n",
    "    Returns:\n",
    "        A string describing the result of the query execution\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"EXECUTING CYPHER QUERY: {description}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Query:\\n{query_str}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "\n",
    "    # Parse the query into individual statements if needed\n",
    "    queries = \" \".join(\n",
    "        [q for q in query_str.splitlines() if not q.strip().startswith(\"//\")]\n",
    "    )\n",
    "    queries = [q.strip() + \";\" for q in queries.split(\";\") if q.strip()]\n",
    "\n",
    "    nodes_created = 0\n",
    "    relationships_created = 0\n",
    "    properties_set = 0\n",
    "    labels_added = 0\n",
    "    indexes_added = 0\n",
    "    constraints_added = 0\n",
    "    response_parts = []\n",
    "\n",
    "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    with driver.session() as session:\n",
    "        for query in queries:\n",
    "            try:\n",
    "                result = session.run(query)\n",
    "                summary = result.consume()\n",
    "\n",
    "                nodes_created += summary.counters.nodes_created\n",
    "                relationships_created += summary.counters.relationships_created\n",
    "                properties_set += summary.counters.properties_set\n",
    "                labels_added += summary.counters.labels_added\n",
    "                indexes_added += summary.counters.indexes_added\n",
    "                constraints_added += summary.counters.constraints_added\n",
    "\n",
    "            except Exception as e:\n",
    "                error_msg = f\"Error executing query: {type(e).__name__}: {str(e)}\"\n",
    "                print(error_msg)\n",
    "                if \"driver\" in locals():\n",
    "                    driver.close()\n",
    "                return error_msg\n",
    "    driver.close()\n",
    "    response_parts.append(f\"Nodes created: {nodes_created}\")\n",
    "    response_parts.append(f\"Relationships created: {relationships_created}\")\n",
    "    response_parts.append(f\"Properties set: {properties_set}\")\n",
    "    response_parts.append(f\"Labels added: {labels_added}\")\n",
    "    response_parts.append(f\"Indexes added: {indexes_added}\")\n",
    "    response_parts.append(f\"Constraints added: {constraints_added}\")\n",
    "\n",
    "    response = \"\\n\".join(response_parts)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"QUERY EXECUTION COMPLETE\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        print(response)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ba919",
   "metadata": {},
   "source": [
    "### An example schema\n",
    "\n",
    "This just sets up the knowledge graph structure, it doesn't ingest any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4fac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"\"\"\n",
    "// === NODE CONSTRAINTS (IDs unique + present) ===\n",
    "CREATE CONSTRAINT case_id_unique IF NOT EXISTS\n",
    "FOR (c:Case) REQUIRE c.id IS UNIQUE;\n",
    "CREATE CONSTRAINT case_id_exists IF NOT EXISTS\n",
    "FOR (c:Case) REQUIRE c.id IS NOT NULL;\n",
    "CREATE CONSTRAINT event_id_unique IF NOT EXISTS\n",
    "FOR (e:Event) REQUIRE e.id IS UNIQUE;\n",
    "CREATE CONSTRAINT event_id_exists IF NOT EXISTS\n",
    "FOR (e:Event) REQUIRE e.id IS NOT NULL;\n",
    "CREATE CONSTRAINT evidence_id_unique IF NOT EXISTS\n",
    "FOR (ev:Evidence) REQUIRE ev.id IS UNIQUE;\n",
    "CREATE CONSTRAINT evidence_id_exists IF NOT EXISTS\n",
    "FOR (ev:Evidence) REQUIRE ev.id IS NOT NULL;\n",
    "CREATE CONSTRAINT location_id_unique IF NOT EXISTS\n",
    "FOR (l:Location) REQUIRE l.id IS UNIQUE;\n",
    "CREATE CONSTRAINT location_id_exists IF NOT EXISTS\n",
    "FOR (l:Location) REQUIRE l.id IS NOT NULL;\n",
    "CREATE CONSTRAINT person_id_unique IF NOT EXISTS\n",
    "FOR (p:Person) REQUIRE p.id IS UNIQUE;\n",
    "CREATE CONSTRAINT person_id_exists IF NOT EXISTS\n",
    "FOR (p:Person) REQUIRE p.id IS NOT NULL;\n",
    "\n",
    "// === RELATIONSHIP PROPERTY EXISTENCE (Enterprise Edition) ===\n",
    "// Person-Person\n",
    "CREATE CONSTRAINT accompanied_by_relationshipType_exists IF NOT EXISTS\n",
    "FOR ()-[r:ACCOMPANIED_BY]-() REQUIRE r.relationshipType IS NOT NULL;\n",
    "\n",
    "// Person-Location (carry dates; time may be optional)\n",
    "CREATE CONSTRAINT attended_party_at_date_exists IF NOT EXISTS\n",
    "FOR ()-[r:ATTENDED_PARTY_AT]-() REQUIRE r.date IS NOT NULL;\n",
    "CREATE CONSTRAINT last_seen_near_date_exists IF NOT EXISTS\n",
    "FOR ()-[r:LAST_SEEN_NEAR]-() REQUIRE r.date IS NOT NULL;\n",
    "CREATE CONSTRAINT lived_at_date_exists IF NOT EXISTS\n",
    "FOR ()-[r:LIVED_AT]-() REQUIRE r.date IS NOT NULL;\n",
    "CREATE CONSTRAINT residence_of_date_exists IF NOT EXISTS\n",
    "FOR ()-[r:RESIDENCE_OF]-() REQUIRE r.date IS NOT NULL;\n",
    "\n",
    "// Evidence-Location (carry dates)\n",
    "CREATE CONSTRAINT found_at_date_exists IF NOT EXISTS\n",
    "FOR ()-[r:FOUND_AT]-() REQUIRE r.date IS NOT NULL;\n",
    "CREATE CONSTRAINT seized_from_date_exists IF NOT EXISTS\n",
    "FOR ()-[r:SEIZED_FROM]-() REQUIRE r.date IS NOT NULL;\n",
    "\n",
    "// Case-related edges typically include optional outcome metadata\n",
    "CREATE INDEX person_name IF NOT EXISTS FOR (p:Person) ON (p.name);\n",
    "CREATE INDEX location_name IF NOT EXISTS FOR (l:Location) ON (l.name);\n",
    "CREATE INDEX case_name IF NOT EXISTS FOR (c:Case) ON (c.name);\n",
    "\"\"\"\n",
    "\n",
    "execute_cypher_query(query_str, description=\"Creating knowledge graph schema\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1312beb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Or ask an agentic system to build it for us!\n",
    "\n",
    "Note: this is not guaranteed to converge, and it may take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab16a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.base import TaskResult\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Configure Azure OpenAI client\n",
    "azure_deployment = \"gpt-5-mini\"  # Replace with your deployment name\n",
    "api_version = \"2024-12-01-preview\"\n",
    "azure_endpoint = \"https://your-resource.openai.azure.com/\"  # Replace with your endpoint\n",
    "api_key = os.getenv(\"AZURE_SUBSCRIPTION_KEY\")  # Set this environment variable\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"AZURE_OPENAI_API_KEY environment variable not set.\")\n",
    "\n",
    "client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=azure_deployment,\n",
    "    model=\"gpt-5-mini\",\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "schema_planner_message = \"\"\"\n",
    "You are a Graph Database Schema Planner. Your job is to analyze the provided data \n",
    "and design an optimal graph database schema for Neo4j.\n",
    "\n",
    "Given the data structure, you should:\n",
    "1. Identify which CSV files should become node types\n",
    "2. Identify which CSV files represent relationships between nodes\n",
    "3. Plan constraints and indexes for efficient querying\n",
    "4. Explain your reasoning clearly\n",
    "5. Consider feedback from the User Proxy\n",
    "\n",
    "Files ending in \"_Rel.csv\" typically represent relationships between entities.\n",
    "Files without \"_Rel\" typically represent node entities.\n",
    "\n",
    "Once you have planned the schema and the User Proxy approves, say \"SCHEMA_READY\" to proceed.\n",
    "\"\"\"\n",
    "\n",
    "schema_creator_message = \"\"\"\n",
    "You are a Graph Database Schema Creator. You receive schema plans and create them\n",
    "in Neo4j using Cypher queries.\n",
    "\n",
    "Your tasks:\n",
    "1. Clear any existing data (use MATCH (n) DETACH DELETE n)\n",
    "2. Create constraints for unique identifiers (use CREATE CONSTRAINT ... IF NOT EXISTS)\n",
    "3. Create indexes for frequently queried properties\n",
    "\n",
    "Use the execute_query tool to run your cypher queries. Provide clear descriptions\n",
    "of what each query does.\n",
    "\n",
    "After creating the schema successfully, say \"SCHEMA_CREATED\" to finish.\n",
    "\"\"\"\n",
    "\n",
    "schema_planner = AssistantAgent(\n",
    "    name=\"SchemaPlanner\",\n",
    "    system_message=schema_planner_message,\n",
    "    model_client=client,\n",
    ")\n",
    "\n",
    "query_tool = lambda query_str, description: execute_cypher_query(\n",
    "    query_str,\n",
    "    description,\n",
    "    verbose=True,  # Enable verbose for detailed output of queries\n",
    ")\n",
    "\n",
    "schema_creator = AssistantAgent(\n",
    "    name=\"SchemaCreator\",\n",
    "    system_message=schema_creator_message,\n",
    "    model_client=client,\n",
    "    tools=[query_tool],\n",
    ")\n",
    "\n",
    "\n",
    "# Run the agentic system\n",
    "async def build_knowledge_graph():\n",
    "    \"\"\"\n",
    "    Runs the agentic system to plan and create schema in Neo4j using round robin.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STARTING AGENTIC KNOWLEDGE GRAPH SCHEMA DESIGN\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    termination = TextMentionTermination(\"SCHEMA_CREATED\")\n",
    "    groupchat = RoundRobinGroupChat(\n",
    "        [schema_planner, schema_creator],\n",
    "        max_turns=100,\n",
    "        termination_condition=termination,\n",
    "    )\n",
    "\n",
    "    # Create the initial task with the data_str (from earlier cell) context\n",
    "    task = f\"\"\"\n",
    "    We need to design and create a Knowledge Graph schema in Neo4j from the following data:\n",
    "\n",
    "    {data_str}\n",
    "\n",
    "    UserProxy: Please review the data and guide the schema design process.\n",
    "    SchemaPlanner: Analyze this data and design an optimal graph schema.\n",
    "    SchemaCreator: Once the schema is approved, create it in Neo4j.\n",
    "\n",
    "    Work together in round robin fashion to complete this task step by step.\n",
    "    \"\"\"\n",
    "\n",
    "    result: TaskResult = await groupchat.run(task=task)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"KNOWLEDGE GRAPH SCHEMA DESIGN COMPLETE\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Execute the agentic system\n",
    "result = await build_knowledge_graph()\n",
    "\n",
    "# Print out all messages from the agents\n",
    "for message in result.messages:\n",
    "    print(f\"{message.content}\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5321154e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Reflection\n",
    "\n",
    "##### What worked well in the schema creation and data inspection?\n",
    "\n",
    "_(Reflect on the helper tool for executing Cypher, your Cypher workflow, and verifying connectivity with the Python driver. What parts felt smooth or intuitive?)_\n",
    "\n",
    "##### What struggled?\n",
    "\n",
    "_(Note where you ran into issues: constraint creation (e.g., enterprise-only relationship property constraints), indexing decisions, schema mismatches with the CSVs, data quality (missing/duplicate IDs), or agentic system loops/timeouts.)_\n",
    "\n",
    "##### Manual Cypher vs. Agentic Schema Creation\n",
    "\n",
    "_(Compare control/transparency, speed/latency, reproducibility, and correctness guarantees. When would you prefer a manual approach, and when might agentic planning be helpful?)_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
