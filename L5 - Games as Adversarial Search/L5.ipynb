{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CSC 480-F25 Lab 5: Games as Adversarial Search (Scrabble Agent)\n",
                "\n",
                "### Authors:\n",
                "***[Team Member 1], [Team Member 2], [Team Member 3]***\n",
                "\n",
                "California Polytechnic State University, San Luis Obispo;\n",
                "Computer Science & Software Engineering Department\n",
                "\n",
                "### Overview\n",
                "This lab covers **Adversarial Search**, beginning with classical Minimax and Alpha-Beta pruning, then transitioning to **Monte Carlo Tree Search (MCTS)** to handle the complexity and imperfect information of Scrabble. We apply the **agentic design approach** (from Lab 2 and the heuristic integration of Lab 4) to construct a sophisticated state evaluation function that guides the MCTS playouts.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Environment Setup and Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "shellscript"
                }
            },
            "outputs": [],
            "source": [
                "# Reusing package install from L4\n",
                "%pip install \"autogen-core\" \"autogen-agentchat\" \"autogen-ext[openai,azure]\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reusing standard imports from L4\n",
                "import os\n",
                "import asyncio\n",
                "import time\n",
                "import random\n",
                "from typing import List, Tuple, Dict, Optional\n",
                "\n",
                "# Import AutoGen classes\n",
                "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
                "from autogen_agentchat.teams import RoundRobinGroupChat\n",
                "from autogen_agentchat.conditions import TextMentionTermination\n",
                "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
                "\n",
                "# Import core game utilities from scrabble_utils.py (must be in the same directory)\n",
                "from L5_utils import ScrabbleState, AlphaBetaMinimax, MonteCarlo, Move "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### First take a look at the Scrabble Implementation\n",
                "\n",
                "The following code randomly selects moves for both players in the Scrabble game until the game terminates.\n",
                "It should give you a sense of what the API looks like."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import random\n",
                "\n",
                "# Initialize the game state\n",
                "game_state = ScrabbleState.create_new_game()\n",
                "print(\"Initial Game State:\")\n",
                "print(game_state)\n",
                "\n",
                "while not game_state.is_terminal():\n",
                "    current_player = game_state.current_player\n",
                "    legal_moves = game_state.get_legal_moves(current_player)\n",
                "\n",
                "    # Prefer non-pass moves if available\n",
                "    non_pass_moves = [move for move in legal_moves if not move.is_pass]\n",
                "    if non_pass_moves:\n",
                "        chosen_move = random.choice(non_pass_moves)\n",
                "    else:\n",
                "        chosen_move = legal_moves[0]  # Must pass if no other\n",
                "    \n",
                "    game_state = game_state.apply_move(chosen_move)\n",
                "    print(f\"\\nPlayer {current_player} plays: {chosen_move}\")\n",
                "    print(game_state)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Azure OpenAI Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reusing configuration from L4.ipynb\n",
                "# Configure your Azure OpenAI client\n",
                "azure_deployment = \"your-deployment-name\"\n",
                "api_version = \"2024-12-01-preview\"\n",
                "azure_endpoint = \"your-azure-endpoint\"\n",
                "\n",
                "# Ensure your API key is set as an environment variable\n",
                "api_key = os.getenv(\"AZURE_SUBSCRIPTION_KEY\")\n",
                "\n",
                "client = AzureOpenAIChatCompletionClient(\n",
                "    azure_deployment=azure_deployment,\n",
                "    model=\"gpt-5-mini\", # Using the default model name referenced in previous labs\n",
                "    api_version=api_version,\n",
                "    azure_endpoint=azure_endpoint,\n",
                "    api_key=api_key,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 1 & 2: Classical Search Limitations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A small note: Minimax and MCTS expect that the problem space is zero-sum. Scrabble is not inherently zero-sum with the typical method scores are calculated. However, we make it zero-sum by using the difference between the two players' scores as the metric to optimize for.\n",
                "\n",
                "### 1. Written Analysis: Why Minimax Fails Scrabble (Part 2)\n",
                "\n",
                "**Task:** Using the concepts of **State Space Size, Branching Factor, and Imperfect Information** (hidden opponent tiles), justify why a naive application of Minimax with Alpha-Beta pruning is impractical for Scrabble.\n",
                "\n",
                "_(Insert written analysis here)_"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Demonstration: Minimax Performance Limits\n",
                "\n",
                "**Task:** Run the `AlphaBetaMinimax` on a simplified Scrabble state. Observe the exploration time and the number of nodes explored, particularly when increasing the `max_depth` to demonstrate the complexity explosion."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize a simple Scrabble state\n",
                "initial_state = ScrabbleState.create_new_game()\n",
                "print(f\"Initial state created. Player 1 Rack: {initial_state.racks}\")\n",
                "\n",
                "# Experiment 1: Shallow Search (Depth 1)\n",
                "print(\"\\n--- Running Minimax (Depth 1) ---\")\n",
                "minimax_d1 = AlphaBetaMinimax(max_depth=1)\n",
                "best_move_d1 = minimax_d1.find_best_move(initial_state)\n",
                "print(f\"Depth 1 suggests: {best_move_d1}\")\n",
                "\n",
                "# Experiment 2: Deeper Search (Depth 3)\n",
                "print(\"\\n--- Running Minimax (Depth 3) ---\")\n",
                "minimax_d3 = AlphaBetaMinimax(max_depth=3)\n",
                "\n",
                "best_move_d3 = minimax_d3.find_best_move(initial_state)\n",
                "print(f\"Depth 3 suggests: {best_move_d3}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 3: Adversarial Monte Carlo Agent"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now check out MCTS with the placeholder heuristic (which currently uses the score + noise)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def basic_scrabble_heuristic(state: ScrabbleState, player: int) -> float:\n",
                "    # Simple heuristic: score + small random noise\n",
                "    base_score = state.scores[player]\n",
                "    noise = random.uniform(-0.1, 0.1)  # Small noise to break ties\n",
                "    return base_score + noise"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Here we're simulating a game between two players. One which uses MCTS to choose it's moves (Player 1) and the other which chooses at random (Player 2)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def run_mcts_match(num_playouts: int, heuristic_fn, num_turns: int = 5):\n",
                "    \"\"\"Initializes and runs the Monte Carlo Agent against a simple opponent.\"\"\"\n",
                "\n",
                "    # MCTS Agent (Player 1) uses the given scrabble_heuristic\n",
                "    mcts = MonteCarlo(num_playouts=num_playouts, heuristic_fn=heuristic_fn)\n",
                "\n",
                "    current_state = ScrabbleState.create_new_game()\n",
                "\n",
                "    print(\n",
                "        f\"Starting Scrabble game simulation for {num_turns} turns. MCTS Agent (P1) uses {int(num_playouts)} playouts.\"\n",
                "    )\n",
                "\n",
                "    for turn in range(num_turns):\n",
                "        if current_state.is_terminal():\n",
                "            break\n",
                "\n",
                "        player_id = current_state.current_player\n",
                "\n",
                "        if player_id == 1:\n",
                "            # Player 1 uses MCTS\n",
                "            print(f\"\\n--- Turn {turn+1}: Player 1 (MCTS) ---\")\n",
                "            move = await mcts.find_best_move(current_state)\n",
                "\n",
                "        else:\n",
                "            # Player 2 makes moves randomly (baseline)\n",
                "            print(f\"\\n--- Turn {turn+1}: Player 2 (Random Baseline) ---\")\n",
                "            possible_moves = current_state.get_legal_moves(player_id)\n",
                "            move = random.choice(possible_moves)\n",
                "\n",
                "        current_state = current_state.apply_move(move)\n",
                "        print(f\"Player {player_id} plays: {move}\")\n",
                "        print(current_state)\n",
                "\n",
                "\n",
                "# Task: Run a baseline MCTS match\n",
                "await run_mcts_match(num_playouts=1e5, heuristic_fn=basic_scrabble_heuristic)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### Agentic Heuristic Design and Impact\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Implement the `collaboratie_heuristic` function using AutoGen agent collaboration.\n",
                "\n",
                "Note: Like previous labs that use an agentic heuristic function, this will take a long time to run. An agentic system for this purpose is impractical due to the overhead of making many LLM calls."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def setup_agentic_heuristic_system(client):\n",
                "    \"\"\"Instantiate heuristic agents for Scrabble state evaluation.\"\"\"\n",
                "\n",
                "    # 1. Define Heuristic Agents (using roles defined in Part 4)\n",
                "    # The system prompts MUST instruct the agents to output a clear numeric score.\n",
                "    score_estimator = AssistantAgent(\n",
                "        name=\"Score_Estimator\",\n",
                "        system_message=\"You calculate the potential points generated by a proposed Scrabble move and potential follow-up points. Provide rationale and end with 'SCORE_EST: <float>'.\",\n",
                "        model_client=client,\n",
                "    )\n",
                "    tile_quality_agent = AssistantAgent(\n",
                "        name=\"Tile_Quality_Agent\",\n",
                "        system_message=\"You analyze the current player's remaining tile rack quality (diversity, future bingo potential) and assign a score. Provide rationale and end with 'SCORE_TILE: <float>'.\",\n",
                "        model_client=client,\n",
                "    )\n",
                "    opponent_risk_agent = AssistantAgent(\n",
                "        name=\"Opponent_Risk_Agent\",\n",
                "        system_message=\"You assess the strategic risk/vulnerability created for the opponent by the current board state (e.g., exposed triple word scores). Provide rationale and end with 'SCORE_RISK: <float>'.\",\n",
                "        model_client=client,\n",
                "    )\n",
                "\n",
                "    # 2. Define the Aggregator Agent (Orchestrator for the heuristic calculation)\n",
                "    mcts_aggregator = AssistantAgent(\n",
                "        name=\"MCTS_Aggregator\",\n",
                "        system_message=\"You receive analyses from the Score, Tile, and Risk agents. Combine their numeric scores using a defined weighting (e.g., Score*0.5 + Tile*0.3 + Risk*0.2) and return a single composite score. Always end your final response with 'FINAL_SCORE: <float>'.\",\n",
                "        model_client=client,\n",
                "    )\n",
                "\n",
                "    return [score_estimator, tile_quality_agent, opponent_risk_agent], mcts_aggregator\n",
                "\n",
                "async def collaborative_heuristic(state: ScrabbleState, player: int) -> float:\n",
                "    heuristic_agents, aggregator = await setup_agentic_heuristic_system(client)\n",
                "\n",
                "    task = f\"Evaluate the strategic value of this Scrabble State for the current player using collaboration:\\n{state}\"\n",
                "\n",
                "    groupchat = RoundRobinGroupChat(\n",
                "        heuristic_agents + [aggregator],\n",
                "        max_turns=3,\n",
                "    )\n",
                "\n",
                "    result = await groupchat.run(task=task)\n",
                "\n",
                "    # Parse the final output from the aggregator\n",
                "    final_output = result.messages[-1].content\n",
                "    try:\n",
                "        score_str = final_output.split(\"FINAL_SCORE:\")[-1].strip()\n",
                "        return float(score_str)\n",
                "    except:\n",
                "        print(\"Warning: Failed to parse final score. Returning baseline.\")\n",
                "        return state.get_utility(state.current_player)\n",
                "\n",
                "# To run the experiment: replace the placeholder function in MCTS Agent\n",
                "await run_mcts_match(num_playouts=3, heuristic_fn=collaborative_heuristic)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Reflection & Analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### What worked well in the Agentic Heuristic System?\n",
                "\n",
                "_(Reflect on the clarity of A2A communication, the effectiveness of the Aggregator, etc.)_\n",
                "\n",
                "##### What struggled?\n",
                "\n",
                "_(Note where agents needed multiple turns, produced inconsistent scores, or struggled to integrate the information.)_\n",
                "\n",
                "##### Agentic vs. Classical Heuristics\n",
                "\n",
                "_(Compare the complexity and potential strength of the composite heuristic created via agent collaboration versus a monolithic Python function, addressing modularity and extensibility.)_"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
